# LLMFlow Environment Variables
# Copy this file to .env and fill in your values

# ===========================================
# Core Settings
# ===========================================

# Proxy server port (receives LLM API requests)
PROXY_PORT=8080

# Dashboard and OTLP ingestion port
DASHBOARD_PORT=3000

# Data directory for SQLite database
DATA_DIR=~/.llmflow

# Maximum traces to retain (older traces are pruned)
MAX_TRACES=10000

# Enable verbose logging (0=off, 1=on)
VERBOSE=0

# ===========================================
# Provider API Keys
# ===========================================

# OpenAI (default provider)
OPENAI_API_KEY=sk-...

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-...

# Google Gemini (either works)
GOOGLE_API_KEY=
GEMINI_API_KEY=

# Cohere
COHERE_API_KEY=

# Groq
GROQ_API_KEY=gsk_...

# Mistral AI
MISTRAL_API_KEY=

# Together AI
TOGETHER_API_KEY=

# Perplexity
PERPLEXITY_API_KEY=pplx-...

# OpenRouter
OPENROUTER_API_KEY=sk-or-...

# ===========================================
# Provider-Specific Settings
# ===========================================

# Ollama (local LLM server)
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# Azure OpenAI
AZURE_OPENAI_RESOURCE=your-resource-name
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_API_VERSION=2024-02-01
# Optional: map models to deployments
# AZURE_DEPLOYMENT_GPT_4=gpt-4-deployment
# AZURE_DEPLOYMENT_GPT_35_TURBO=gpt-35-turbo-deployment

# ===========================================
# OTLP Export Settings
# ===========================================
# Export traces/logs/metrics to external observability backends
# Supports: Jaeger, Phoenix/Arize, Langfuse, Opik, Grafana Tempo, etc.

# Enable OTLP export (auto-enabled if any endpoint is set)
# OTLP_EXPORT_ENABLED=true

# Primary export endpoint (for traces, or all signals)
# OTLP_EXPORT_ENDPOINT=http://localhost:4318/v1/traces

# Signal-specific endpoints (optional)
# OTLP_EXPORT_TRACES_ENDPOINT=http://localhost:4318/v1/traces
# OTLP_EXPORT_LOGS_ENDPOINT=http://localhost:4318/v1/logs
# OTLP_EXPORT_METRICS_ENDPOINT=http://localhost:4318/v1/metrics

# Export headers (comma-separated key=value pairs)
# Examples:
# Jaeger: (no auth needed for local)
# Langfuse: Authorization=Basic base64(pk:sk)
# Phoenix: space_id=xxx,api_key=xxx
# Opik: Authorization=your-api-key,projectName=your-project
# OTLP_EXPORT_HEADERS=Authorization=Bearer xxx,X-Custom-Header=value

# Batching configuration
# OTLP_EXPORT_BATCH_SIZE=100
# OTLP_EXPORT_FLUSH_INTERVAL=5000
