{
  "name": "llmflow-mvp",
  "version": "0.1.0",
  "description": "Simple LLM observability proxy - capture and visualize LLM API calls",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "node server.js",
    "test": "cd example && node chat-simulation.js"
  },
  "dependencies": {
    "express": "^4.18.0",
    "uuid": "^9.0.0"
  },
  "keywords": [
    "llm",
    "observability",
    "proxy",
    "openai",
    "monitoring"
  ],
  "author": "LLMFlow",
  "license": "MIT"
}
